{"cells":[{"cell_type":"markdown","source":["# Finding Causality in Big Data"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"markdown","source":["## Import required libraries and data"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport statsmodels.stats.api as sms\nfrom sklearn.linear_model import LogisticRegression\nimport statsmodels.api as sm\nimport matplotlib.pyplot as plt\nfrom scipy.stats import binom, hypergeom, gaussian_kde\nfrom scipy.stats import ttest_ind\nimport math\nfrom numpy import linalg\nimport scipy.spatial.distance as ssdist\nimport statsmodels.genmod.generalized_linear_model as sm"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["# Attributes:\n\n* school - student's school (binary: \"GP\" - Gabriel Pereira or \"MS\" - Mousinho da Silveira)\n* sex - student's sex (binary: \"F\" - female or \"M\" - male)\n* age - student's age (numeric: from 15 to 22)\n* address - student's home address type (binary: \"U\" - urban or \"R\" - rural)\n* famsize - family size (binary: \"LE3\" - less or equal to 3 or \"GT3\" - greater than 3)\n* Pstatus - parent's cohabitation status (binary: \"T\" - living together or \"A\" - apart)\n* Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n* Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)\n* Mjob - mother's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n* Fjob - father's job (nominal: \"teacher\", \"health\" care related, civil \"services\" (e.g. administrative or police), \"at_home\" or \"other\")\n* reason - reason to choose this school (nominal: close to \"home\", school \"reputation\", \"course\" preference or \"other\")\n* guardian - student's guardian (nominal: \"mother\", \"father\" or \"other\")\n* traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n* studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n* failures - number of past class failures (numeric: n if 1<=n<3, else 4)\n* schoolsup - extra educational support (binary: yes or no)\n* famsup - family educational support (binary: yes or no)\n* paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n* activities - extra-curricular activities (binary: yes or no)\n* nursery - attended nursery school (binary: yes or no)\n* higher - wants to take higher education (binary: yes or no)\n* internet - Internet access at home (binary: yes or no)\n* romantic - with a romantic relationship (binary: yes or no)\n* famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n* freetime - free time after school (numeric: from 1 - very low to 5 - very high)\n* goout - going out with friends (numeric: from 1 - very low to 5 - very high)\n* Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n* Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n* health - current health status (numeric: from 1 - very bad to 5 - very good)\n* absences - number of school absences (numeric: from 0 to 93)\n\n### These grades are related with the course subject, Math or Portuguese:\n* G1 - first period grade (numeric: from 0 to 20)\n* G2 - second period grade (numeric: from 0 to 20)\n* G3 - final grade (numeric: from 0 to 20, output target)"],"metadata":{}},{"cell_type":"code","source":["# 1. read data\ndf = sqlContext.sql(\"SELECT * FROM student_mat\").toPandas()\ndf = df.drop(['G1','G2'],1)\nprint(df.columns)\nprint(df.shape) # 382 students\ndf.head()"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":["# 2. convert all attributes into integer\n# to do: store mappings for each attribute in a dictionary\nfor col in df:\n    if (df[col].dtypes == object) == True:\n        new_map = dict(zip(df[col].unique(),range(len(df[col].unique()))))\n        df[col] = df[col].map(new_map)\ndf.head()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["* Outcome: Final grade\n* Treatment: paid - extra paid classes within the course subject (binary: yes or no)\n* Covariates: all the other attributes"],"metadata":{}},{"cell_type":"markdown","source":["## Define treatment, outcome and covariates"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["df.head()"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# treatment\nTREAT = 'paid'\nTr = df[TREAT]\n\n# outcome\nOUT = 'G3'"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["# 1 Identify covariates from observational data\n## 1.1 Difference-in-means: outcome variable\n\n* Effectiveness of treatment (effect on RE78 expression)\n* Question: does treatment affect RE78 expression (outcome)?"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["df.groupby(TREAT).size()"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":["df.groupby(TREAT)[OUT].mean().reset_index()"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":["# t-statistic & p-value for difference in outcome of two groups\ndef hypothesisTest(data, attribute, group):\n    x = data[attribute][df[group]== 1]\n    y = data[attribute][df[group]== 0]\n    # t-statistic & p-value for difference in outcome of two groups\n    t = ttest_ind(x, y)[0]\n    p = ttest_ind(x, y)[1]\n    # Confidence intervals\n    cm = sms.CompareMeans(sms.DescrStatsW(x), sms.DescrStatsW(y))\n    CI = str(round(cm.tconfint_diff(usevar='unequal')[0]))+' - '+str(round(cm.tconfint_diff(usevar='unequal')[1]))\n    # Cohen's d\n    pooledvar = math.sqrt((pow(x.std(),2) + (pow(y.std(),2)))/2)\n    d = (x.mean()-y.mean()) / pooledvar\n    # create dataframe\n    tablelist = []\n    tablerow = [attribute,x.mean()-y.mean(),t,p,CI,d]\n    tablelist.append(tablerow)\n    out = pd.DataFrame(tablelist)\n    out.columns = ['Attribute','Mean Difference','t-value','p-value','95% Confidence Intervals',\"Cohen's d\"]\n\n    return out"],"metadata":{"collapsed":true,"slideshow":{"slide_type":"slide"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":["# covariates\nb = pd.DataFrame()\nfor att in df.drop([TREAT,OUT],1):\n    a = []\n    a = Test_Class.hypothesisTest(df, att, TREAT)\n    b = pd.concat([b,a],0)\nb.sort('p-value')"],"metadata":{"collapsed":false,"scrolled":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# covariates\nCOV = np.array(b.Attribute[b['p-value'] <= 0.05])\nX = df[COV]\nX.head()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["## 2.1 Propensity score matching"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["####### Using GLM\nglm_binom = sm.GLM(Tr, X, family=sm.families.Binomial())\nres = glm_binom.fit()\nprint res.summary()\npropensityScoreGLM = res.fittedvalues\ndf_new = pd.concat([df[COV],df[OUT],propensityScoreGLM],1)\ndf_new.columns = np.append(COV, [OUT,'Propensity Score'], axis=None )\nprint '\\n'+ 'Propensity Scores added: '\ndf_new.head()"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["## Matching \n\nThere are several variants of matching: \n* one-to-one matching\n* one-to-many matching \n* with or without a caliper, and with or without replacement"],"metadata":{}},{"cell_type":"code","source":["def Match(groups, propensity, caliper = 0.05, caliper_method = \"propensity\", replace = False):\n        \n    # Code groups as 0 and 1\n    groups = groups == groups.unique()[0]\n    N = len(groups)\n    N1 = groups[groups == 1].index; N2 = groups[groups == 0].index\n    g1, g2 = propensity[groups == 1], propensity[groups == 0]\n    # Check if treatment groups got flipped - the smaller should correspond to N1/g1\n    if len(N1) > len(N2):\n       N1, N2, g1, g2 = N2, N1, g2, g1\n        \n    # Randomly permute the smaller group to get order for matching\n    morder = np.random.permutation(N1)\n    matches = {}\n    \n    for m in morder:\n        dist = abs(g1[m] - g2)\n        if (dist.min() <= caliper) or not caliper:\n            matches[m] = dist.argmin()    # Potential problem: check for ties\n            if not replace:\n                g2 = g2.drop(matches[m])\n    return (matches)\n\ndef MatchMany(groups, propensity, method = \"caliper\", k = 1, caliper = 0.05, caliper_method = \"propensity\", replace = True):\n    \n    # Transform the propensity scores and caliper when caliper_method is \"logit\" or \"none\"\n    if method == \"caliper\":\n        if caliper_method == \"logit\":\n            propensity = log(propensity/(1-propensity))\n            caliper = caliper*np.std(propensity)\n        elif caliper_method == \"none\":\n            caliper = 0\n    \n    # Code groups as 0 and 1\n    groups = groups == groups.unique()[0]\n    N = len(groups)\n    N1 = groups[groups == 1].index; N2 = groups[groups == 0].index\n    g1, g2 = propensity[groups == 1], propensity[groups == 0]\n    # Check if treatment groups got flipped - the smaller should correspond to N1/g1\n    if len(N1) > len(N2):\n       N1, N2, g1, g2 = N2, N1, g2, g1\n        \n        \n    # Randomly permute the smaller group to get order for matching\n    morder = np.random.permutation(N1)\n    matches = {}\n    \n    for m in morder:\n        dist = abs(g1[m] - g2)\n        dist.sort()\n        if method == \"knn\":\n            caliper = dist.iloc[k-1]\n        # PROBLEM: when there are ties in the knn. \n        # Need to randomly select among the observations tied for the farthest eacceptable distance\n        keep = np.array(dist[dist<=caliper].index)\n        if len(keep):\n            matches[m] = keep\n        else:\n            matches[m] = [dist.argmin()]\n        if not replace:\n            g2 = g2.drop(matches[m])\n    return (matches)  \n\ndef whichMatched(matches, data, many = False):\n  \n    tr = matches.keys()\n    if many:\n        ctrl = [m for matchset in matches.values() for m in matchset]\n    else:\n        ctrl = matches.values()\n    # need to remove duplicate rows, which may occur in matching with replacement\n    temp = pd.concat([data.ix[tr], data.ix[ctrl]])\n\n    return temp"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["# one-to-one without caliper, without replacement\nmatches = Match(Tr, propensityScoreGLM, caliper = 0, caliper_method = \"propensity\", replace = False)\ntemp = whichMatched(matches, df, many = False)\n\nPS_matched = temp.groupby(temp.index).first()\nPS_matched.groupby(TREAT).size().reset_index()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":21},{"cell_type":"code","source":["# Exercise: Run one-to-one matching with fixed 0.05 caliper, without replacement\nmatches = 'one-to-one matching with caliper, with replacement'\ntemp = 'matched data'\n\nPS_matched1 = temp.groupby(temp.index).first()\nPS_matched1.groupby(TREAT).size().reset_index()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# Exercise: Run one-to-one matching with logit caliper, without replacement\nmatches = 'one-to-one matching with caliper, with replacement'\ntemp = 'matched data'\n\nPS_matched2 = temp.groupby(temp.index).first()\nPS_matched2.groupby(TREAT).size().reset_index()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["# Exercise: Run one-to-one matching with logit caliper, with replacement\nmatches = 'one-to-one matching with caliper, with replacement'\ntemp = 'matched data'\n\nPS_matched3 = temp.groupby(temp.index).first()\nPS_matched3.groupby(TREAT).size().reset_index()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# Exercise: Run one-to-many matching with caliper, with replacement\nmatches = 'one-to-many matching with logit caliper, with replacement'\ntemp = 'matched data'\n\nPS_matched4 = temp.groupby(temp.index).first()\nPS_matched4.groupby(TREAT).size().reset_index()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":25},{"cell_type":"code","source":["# Exercise: Run one-to-many matching with fixed 0.05 caliper, with replacement\nmatches = 'one-to-many matching with fixed 0.05 caliper, with replacement'\ntemp = 'matched data'\n\nPS_matched5 = temp.groupby(temp.index).first()\nPS_matched5.groupby(TREAT).size().reset_index()"],"metadata":{"collapsed":false},"outputs":[],"execution_count":26},{"cell_type":"code","source":["# Exercise: Run one-to-many matching with fixed 0.05 caliper, without replacement\nmatches = 'one-to-many matching with fixed 0.05 caliper, without replacement'\ntemp = 'matched data'\n\nPS_matched6 = temp.groupby(temp.index).first()\nPS_matched6.groupby(TREAT).size().reset_index()"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["# 5 Evaluating matching methods\n\n* Normalize each matched attribute to 0-1\n* Find the difference of means between treatment and control groups"],"metadata":{}},{"cell_type":"code","source":["f = plt.figure(figsize=(15,5))\n\nPS_matched_norm = (PS_matched[COV] - PS_matched[COV].mean()) / (PS_matched[COV].max() - PS_matched[COV].min())\nPS_matched_mean = pd.DataFrame({'mean':abs(PS_matched_norm[PS_matched[TREAT]==1].mean() - PS_matched_norm[PS_matched[TREAT]==0].mean())}).mean()[0]\n\nPS_matched_norm = (PS_matched1[COV] - PS_matched1[COV].mean()) / (PS_matched1[COV].max() - PS_matched1[COV].min())\nPS_matched_mean1 = pd.DataFrame({'mean':abs(PS_matched_norm[PS_matched1[TREAT]==1].mean() - PS_matched_norm[PS_matched1[TREAT]==0].mean())}).mean()[0]\n\nPS_matched_norm = (PS_matched2[COV] - PS_matched2[COV].mean()) / (PS_matched2[COV].max() - PS_matched2[COV].min())\nPS_matched_mean2 = pd.DataFrame({'mean':abs(PS_matched_norm[PS_matched2[TREAT]==1].mean() - PS_matched_norm[PS_matched2[TREAT]==0].mean())}).mean()[0]\n\nPS_matched_norm = (PS_matched3[COV] - PS_matched3[COV].mean()) / (PS_matched3[COV].max() - PS_matched3[COV].min())\nPS_matched_mean3 = pd.DataFrame({'mean':abs(PS_matched_norm[PS_matched3[TREAT]==1].mean() - PS_matched_norm[PS_matched3[TREAT]==0].mean())}).mean()[0]\n\nPS_matched_norm = (PS_matched4[COV] - PS_matched4[COV].mean()) / (PS_matched4[COV].max() - PS_matched4[COV].min())\nPS_matched_mean4 = pd.DataFrame({'mean':abs(PS_matched_norm[PS_matched4[TREAT]==1].mean() - PS_matched_norm[PS_matched4[TREAT]==0].mean())}).mean()[0]\n\nPS_matched_norm = (PS_matched5[COV] - PS_matched5[COV].mean()) / (PS_matched5[COV].max() - PS_matched5[COV].min())\nPS_matched_mean5 = pd.DataFrame({'mean':abs(PS_matched_norm[PS_matched4[TREAT]==1].mean() - PS_matched_norm[PS_matched4[TREAT]==0].mean())}).mean()[0]\n\nPS_matched_norm = (PS_matched6[COV] - PS_matched6[COV].mean()) / (PS_matched6[COV].max() - PS_matched6[COV].min())\nPS_matched_mean6 = pd.DataFrame({'mean':abs(PS_matched_norm[PS_matched4[TREAT]==1].mean() - PS_matched_norm[PS_matched4[TREAT]==0].mean())}).mean()[0]\n\n\nx = [PS_matched.shape[0],PS_matched1.shape[0],PS_matched2.shape[0],PS_matched3.shape[0],PS_matched4.shape[0],,PS_matched5.shape[0],,PS_matched6.shape[0]]\ny = [PS_matched_mean ,PS_matched_mean1,PS_matched_mean2,PS_matched_mean3,PS_matched_mean4,PS_matched_mean5,PS_matched_mean6]\ncolors = ['r','b','g','c','k','m','y']\nMatchingMethod = ['1-1 wC woutR','1-1 wC woutR','1-1 wC woutR','1-1 wC wR','1-m wC wR','1-m wC wR','1-m wC woutR']\n\nj = 0\nfor i in x:\n    plt.scatter(i, y[j], s=120, c=colors[j], label=MatchingMethod[j])\n    j += 1\n    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5),ncol=1, fancybox=True, fontsize=8)\n    \nplt.xlabel('Sample Size')\nplt.ylabel('Balance Metric')\n\ndisplay(f)"],"metadata":{"collapsed":false},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["## 5 Estimate treatment effects\n\nEstimate average treatment effect  on the treated\n\n### 5.1 Computes ATT using difference in means"],"metadata":{"slideshow":{"slide_type":"slide"}}},{"cell_type":"code","source":["# t-statistic & p-value for difference in outcome of two groups\ndef hypothesisTestOutcome(data, attribute, group):\n    x = data[attribute][df[group]== 1]\n    y = data[attribute][df[group]== 0]\n    # t-statistic & p-value for difference in outcome of two groups\n    t = ttest_ind(x, y)[0]\n    p = ttest_ind(x, y)[1]\n    # Confidence intervals\n    cm = sms.CompareMeans(sms.DescrStatsW(x), sms.DescrStatsW(y))\n    CI = str(round(cm.tconfint_diff(usevar='unequal')[0]))+' - '+str(round(cm.tconfint_diff(usevar='unequal')[1]))\n    # Cohen's d\n    pooledvar = math.sqrt((pow(x.std(),2) + (pow(y.std(),2)))/2)\n    d = (x.mean()-y.mean()) / pooledvar\n    # create dataframe\n    tablelist = []\n    tablerow = [attribute,x.mean()-y.mean(),((x.mean()-y.mean())/df[attribute].max()),t,p,d]\n    tablelist.append(tablerow)\n    out = pd.DataFrame(tablelist)\n    out.columns = ['Attribute','Outcome Mean Difference','Outcome Mean Difference %','t-value','p-value',\"Cohen's d\"]\n\n    return out"],"metadata":{},"outputs":[],"execution_count":31},{"cell_type":"code","source":["# Matched outcome\nY0_PS_matched = PS_matched.G3[df.paid == 0]\nY1_PS_matched = PS_matched.G3[df.paid == 1]\n\n# Exercise: compute the difference in means for matched groups\nprint 'Differene in means: '+ str('compute the difference in means for matched groups')"],"metadata":{"collapsed":false,"slideshow":{"slide_type":"fragment"}},"outputs":[],"execution_count":32}],"metadata":{"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython2","codemirror_mode":{"name":"ipython","version":2.0},"version":"2.7.10","nbconvert_exporter":"python","file_extension":".py"},"name":"Causal-Inference-Python-Exercise","notebookId":34564,"kernelspec":{"display_name":"Python 2","language":"python","name":"python2"},"celltoolbar":"Slideshow"},"nbformat":4,"nbformat_minor":0}
